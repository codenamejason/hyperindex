module InMemoryStore = {
  type stringHasher<'val> = 'val => string

  type storeStateEntity<'entity, 'entityKey> = {
    dict: Js.Dict.t<Types.inMemoryStoreRowEntity<'entity>>,
    hasher: stringHasher<'entityKey>,
  }

  type storeStateMeta<'entity, 'entityKey> = {
    dict: Js.Dict.t<Types.inMemoryStoreRowMeta<'entity>>,
    hasher: stringHasher<'entityKey>,
  }

  module type StoreItem = {
    type t
    type key
    let hasher: stringHasher<key>
  }

  //Binding used for deep cloning stores in tests
  @val external structuredClone: 'a => 'a = "structuredClone"

  module MakeStoreEntity = (StoreItem: StoreItem) => {
    @genType
    type value = StoreItem.t
    @genType
    type key = StoreItem.key
    type t = storeStateEntity<value, key>

    let make = (): t => {dict: Js.Dict.empty(), hasher: StoreItem.hasher}

    // NOTE: calling initValue on an existing store item will override it. This function does no checks to make sure there isn't existing data that can get lost.
    let initValue = (self: t, ~key: StoreItem.key, ~entity: option<StoreItem.t>) => {
      let initialStoreRow: Types.inMemoryStoreRowEntity<StoreItem.t> = switch entity {
      | Some(entity) => ReadNoChangeFromDB(AlreadySet(entity))
      | None => ReadNoChangeFromDB(NotSet)
      }
      self.dict->Js.Dict.set(key->self.hasher, initialStoreRow)
    }

    let set = (self: t, ~key: StoreItem.key, ~entity: Types.entityUpdate<StoreItem.t>) => {
      // let getOptEventIdentifier = (entity: Types.entityCurrentState<StoreItem.t>) => {
      //   switch entity {
      //   | Updated(Delete(_, eventIdentifier))
      //   | Updated(Set(_, eventIdentifier)) =>
      //     Some(eventIdentifier)
      //   | ReadNoChangeFromDB => None
      //   }
      // }
      if Config.placeholder_is_near_head_of_chain_or_in_dev_mode {
        let mapKey = key->self.hasher
        let currentEntity = self.dict->Js.Dict.get(mapKey)
        let entityData: Types.inMemoryStoreRowEntity<StoreItem.t> = switch currentEntity {
        | Some(ReadNoChangeFromDB(_)) => Obj.magic()
        | Some(Updated(_)) => Obj.magic()
        | None => Obj.magic()
        }
        // switch (currentEntity, entity) {
        //   | (Some(existingEntityUpdate), Delete(eventId, eventIdentifier)) =>
        //
        // }
        /*
        let entityData: Types.inMemoryStoreRowEntity<StoreItem.t> = switch currentEntity {
        | Some(existingEntityUpdate) =>
          switch entity {
          | Delete(_, eventIdentifier)
          | Set(_, eventIdentifier) =>
            // Use -1 as defaults for now
            let oldEntityIdentifier = getOptEventIdentifier(
              existingEntityUpdate.current,
            )->Belt.Option.getWithDefault({
              chainId: -1,
              blockNumber: -1,
              logIndex: -1,
            })
            if (
              eventIdentifier.blockNumber == oldEntityIdentifier.blockNumber &&
                eventIdentifier.logIndex == oldEntityIdentifier.logIndex
            ) {
              // If it is in the same event, override the current event with the new one
              {
                ...existingEntityUpdate,
                current: entity,
              }
            } else {
              // in a different event, add it to the history.
              {
                current: entity,
                history: existingEntityUpdate.history->Belt.Array.concat([
                  existingEntityUpdate.current,
                ]),
                valueAtStartOfBatch: NotSet /* TODO */,
              }
            }
          | Read(Some(existingEntity)) => {
              current: entity,
              history: existingEntityUpdate.history,
              valueAtStartOfBatch: AlreadySet(existingEntity),
            }
          | Read(None) => {
              current: entity,
              history: existingEntityUpdate.history,
              valueAtStartOfBatch: NotSet,
            }
          }
        | None => // This means the entity is being set, but it was never checked if there is an existing entity in the DB.
          {
            current: entity,
            history: [],
            valueAtStartOfBatch: NotSet /* TODO */,
          }
        }*/
        self.dict->Js.Dict.set(mapKey, entityData)
      } else {
        //Wont do for hackathon
        ()
      }
    }

    let get = (self: t, key: StoreItem.key) =>
      self.dict
      ->Js.Dict.get(key->self.hasher)
      ->Belt.Option.flatMap(row => {
        switch row {
        | Updated({latest: Set(entity, _)}) => Some(entity)
        | Updated({latest: Delete(_)}) => None
        | ReadNoChangeFromDB(AlreadySet(entity)) => Some(entity)
        | ReadNoChangeFromDB(NotSet) => None
        }
      })

    let values = (self: t) => self.dict->Js.Dict.values

    let clone = (self: t) => {
      ...self,
      dict: self.dict->structuredClone,
    }
  }

  module MakeStoreMeta = (StoreItem: StoreItem) => {
    @genType
    type value = StoreItem.t
    @genType
    type key = StoreItem.key
    type t = storeStateMeta<value, key>

    let make = (): t => {dict: Js.Dict.empty(), hasher: StoreItem.hasher}

    let set = (self: t, ~key: StoreItem.key, ~entity: StoreItem.t) =>
      self.dict->Js.Dict.set(key->self.hasher, entity)

    let get = (self: t, key: StoreItem.key) =>
      self.dict->Js.Dict.get(key->self.hasher)->Belt.Option.map(row => row)

    let values = (self: t) => self.dict->Js.Dict.values

    let clone = (self: t) => {
      ...self,
      dict: self.dict->structuredClone,
    }
  }

  module EventSyncState = MakeStoreMeta({
    type t = DbFunctions.EventSyncState.eventSyncState
    type key = int
    let hasher = Belt.Int.toString
  })

  @genType
  type rawEventsKey = {
    chainId: int,
    eventId: string,
  }

  module RawEvents = MakeStoreMeta({
    type t = Types.rawEventsEntity
    type key = rawEventsKey
    let hasher = (key: key) =>
      EventUtils.getEventIdKeyString(~chainId=key.chainId, ~eventId=key.eventId)
  })

  @genType
  type dynamicContractRegistryKey = {
    chainId: int,
    contractAddress: Ethers.ethAddress,
  }

  module DynamicContractRegistry = MakeStoreMeta({
    type t = Types.dynamicContractRegistryEntity
    type key = dynamicContractRegistryKey
    let hasher = ({chainId, contractAddress}) =>
      EventUtils.getContractAddressKeyString(~chainId, ~contractAddress)
  }){{#each entities as | entity |}}

  module {{entity.name.capitalized}} = MakeStoreEntity({
    type t = Types.{{entity.name.uncapitalized}}Entity
    type key = string
    let hasher = Obj.magic
  })

{{/each}}

  @genType 
  type t = {
    eventSyncState: EventSyncState.t,
    rawEvents: RawEvents.t,
    dynamicContractRegistry: DynamicContractRegistry.t,
  {{#each entities as | entity |}}
    {{entity.name.uncapitalized}}: {{entity.name.capitalized}}.t,
  {{/each}}
  }

  let make = (): t => {
    eventSyncState: EventSyncState.make(),
    rawEvents: RawEvents.make(),
    dynamicContractRegistry: DynamicContractRegistry.make(),
  {{#each entities as | entity |}}
    {{entity.name.uncapitalized}}: {{entity.name.capitalized}}.make(),
  {{/each}}
  }

  let clone = (self: t) => {
    eventSyncState: self.eventSyncState->EventSyncState.clone,
    rawEvents: self.rawEvents->RawEvents.clone,
    dynamicContractRegistry: self.dynamicContractRegistry->DynamicContractRegistry.clone,
  {{#each entities as | entity |}}
    {{entity.name.uncapitalized}}: self.{{entity.name.uncapitalized}}->{{entity.name.capitalized}}.clone,
  {{/each}}
  }
}


module LoadLayer = {
  /**The ids to load for a particular entity*/
  type idsToLoad = Belt.Set.String.t

  /**
  A round of entities to load from the DB. Depending on what entities come back
  and the dataLoaded "actions" that get run after the entities are loaded up. It
  could mean another load layer is created based of values that are returned
  */
  type rec t = {
    //A an array of getters to run after the entities with idsToLoad have been loaded
    dataLoadedActionsGetters: dataLoadedActionsGetters,
  {{#each entities as | entity |}}
    //A unique list of ids that need to be loaded for entity {{entity.name.uncapitalized}}
    {{entity.name.uncapitalized}}IdsToLoad: idsToLoad,
  {{/each}}
  }
  //An action that gets run after the data is loaded in from the db to the in memory store
  //the action will derive values from the loaded data and update the next load layer
  and dataLoadedAction = t => t
  //A getter function that returns an array of actions that need to be run
  //Actions will fetch values from the in memory store and update a load layer
  and dataLoadedActionsGetter = unit => array<dataLoadedAction>
  //An array of getter functions for dataLoadedActions
  and dataLoadedActionsGetters = array<dataLoadedActionsGetter>

  /**Instantiates a load layer*/
  let emptyLoadLayer = () => {
  {{#each entities as | entity |}}
    {{entity.name.uncapitalized}}IdsToLoad: Belt.Set.String.empty,
  {{/each}}
    dataLoadedActionsGetters: [],
  }

  /*Helper to append an ID to load for a given entity to the loadLayer*/
  let extendIdsToLoad = (idsToLoad: idsToLoad, entityId: Types.id): idsToLoad =>
    idsToLoad->Belt.Set.String.add(entityId)

  /*Helper to append a getter for DataLoadedActions to load for a given entity to the loadLayer*/
  let extendDataLoadedActionsGetters = (
    dataLoadedActionsGetters: dataLoadedActionsGetters,
    newDataLoadedActionsGetters: dataLoadedActionsGetters,
  ): dataLoadedActionsGetters =>
    dataLoadedActionsGetters->Belt.Array.concat(newDataLoadedActionsGetters)
}

/**
Loader functions for each entity. The loader function extends a load layer with the given id and config.
*/
@warning("-39") //remove warning 39 for unused "rec" flag in case of no other related loaders
let rec{{#each entities as | entity |}}{{#unless @first}}@warning("-27") and {{/unless}} {{entity.name.uncapitalized}}LinkedEntityLoader = (
  loadLayer: LoadLayer.t,
  ~entityId: string,
  ~inMemoryStore: InMemoryStore.t,
  ~{{entity.name.uncapitalized}}LoaderConfig: Types.{{entity.name.uncapitalized}}LoaderConfig,
): LoadLayer.t => {
  {{#if entity.relational_params.filtered_not_derived_from.[0]}}
  //An array of getter functions for dataLoaded actions that will be run
  //after the current load layer is executed

  let dataLoadedActionsGetters = [
  {{#each entity.relational_params.filtered_not_derived_from as | relational_param |}}
    {{entity.name.uncapitalized}}LoaderConfig.load{{relational_param.relational_key.capitalized}}->Belt.Option.map({{relational_param.mapped_entity.uncapitalized}}LoaderConfig => {
      () =>
      inMemoryStore.{{entity.name.uncapitalized}}
      ->InMemoryStore.{{entity.name.capitalized}}.get(entityId)
      ->Belt.Option.mapWithDefault([],entity => {
        //getLoader can be used to map arrays of ids, optional ids or single ids
        let getLoader = 
              (entityId) => 
                {{relational_param.mapped_entity.uncapitalized}}LinkedEntityLoader(
                    ~{{relational_param.mapped_entity.uncapitalized}}LoaderConfig,
                    ~entityId,
                    ~inMemoryStore
                  )
    {{#if (eq relational_param.relationship_type "array")}}
        entity.{{relational_param.relational_key.uncapitalized}}->Belt.Array.map(entityId => entityId->getLoader)
    {{else}}
      {{#if relational_param.is_optional}}
        //In this case entity.{{relational_param.relational_key.uncapitalized}} is an optional single value. But we
        //still pass back an array of actions in order for cases where the related entity is an array of ids
        entity.{{relational_param.relational_key.uncapitalized}}_id->Belt.Option.mapWithDefault([], entityId => [entityId->getLoader])
      {{else}}
        //In this case entity.{{relational_param.relational_key.uncapitalized}} is a single value. But we
        //still pass back an array of actions in order for cases where the related entity is an array of ids
        [entity.{{relational_param.relational_key.uncapitalized}}_id->getLoader]
      {{/if}}
    {{/if}}
      })
    }),
  {{/each}}
    ]->Belt.Array.keepMap(v => v)

  {
    ...loadLayer,
    {{entity.name.uncapitalized}}IdsToLoad: loadLayer.{{entity.name.uncapitalized}}IdsToLoad->LoadLayer.extendIdsToLoad(entityId),
    dataLoadedActionsGetters: loadLayer.dataLoadedActionsGetters->LoadLayer.extendDataLoadedActionsGetters(
      dataLoadedActionsGetters,
    ),
  }
  {{else}}
  //No dataLoaded actions need to happen on the in memory
  //since there are no relational non-derivedfrom params
  let _ = inMemoryStore //ignore inMemoryStore and stop warning
  //In this case the "{{entity.name.uncapitalized}}LoaderConfig" type is a boolean.
  if !{{entity.name.uncapitalized}}LoaderConfig {
    //If {{entity.name.uncapitalized}}LoaderConfig is false, don't load the entity
    //simply return the current load layer
    loadLayer
  } else {
    //If {{entity.name.uncapitalized}}LoaderConfig is true, 
    //extend the entity ids to load field
    //There can be no dataLoadedActionsGetters to add since this type does not contain
    //any non derived from relational params
    {
      ...loadLayer,
      {{entity.name.uncapitalized}}IdsToLoad: loadLayer.{{entity.name.uncapitalized}}IdsToLoad->LoadLayer.extendIdsToLoad(entityId),
    }
  }
  {{/if}}
}
{{/each}}

/**
Creates and populates a load layer with the current in memory store and an array of entityRead variants
*/
let getLoadLayer = (~entityBatch: array<Types.entityRead>, ~inMemoryStore) => {
  entityBatch->Belt.Array.reduce(LoadLayer.emptyLoadLayer(), (loadLayer, readEntity) => {
    switch readEntity {
    {{#each entities as | entity |}}
    | {{entity.name.capitalized}}Read(entityId{{#if entity.relational_params.filtered_not_derived_from.[0]}}, {{entity.name.uncapitalized}}LoaderConfig{{/if}}) =>
      loadLayer->{{entity.name.uncapitalized}}LinkedEntityLoader(~entityId, ~inMemoryStore, ~{{entity.name.uncapitalized}}LoaderConfig{{#unless entity.relational_params.filtered_not_derived_from.[0]}}=true{{/unless}})
    {{/each}}
    }
  })
}

/**
Represents whether a deeper layer needs to be executed or whether the last layer
has been executed
*/
type nextLayer = NextLayer(LoadLayer.t) | LastLayer

let getNextLayer = (~loadLayer: LoadLayer.t) =>
  switch loadLayer.dataLoadedActionsGetters {
  | [] => LastLayer
  | dataLoadedActionsGetters =>
    dataLoadedActionsGetters
    ->Belt.Array.reduce(LoadLayer.emptyLoadLayer(), (loadLayer, getLoadedActions) => {
      //call getLoadedActions returns array of of actions to run against the load layer
      getLoadedActions()->Belt.Array.reduce(loadLayer, (loadLayer, action) => {
        action(loadLayer)
      })
    })
    ->NextLayer
  }

/**
Used for composing a loadlayer executor
*/
type entityExecutor<'executorRes> = {
  idsToLoad: LoadLayer.idsToLoad,
  executor: LoadLayer.idsToLoad => 'executorRes,
}

/**
Compose an execute load layer function. Used to compose an executor
for a postgres db or a mock db in the testing framework.
*/
let executeLoadLayerComposer = (
  ~entityExecutors: array<entityExecutor<'exectuorRes>>,
  ~handleResponses: array<'exectuorRes> => 'nextLoadlayer,
) => {
  entityExecutors
  ->Belt.Array.map(({idsToLoad, executor}) => {
    idsToLoad->executor
  })
  ->handleResponses
}


/**Recursively load layers with execute fn composer. Can be used with async or sync functions*/
let rec executeNestedLoadLayersComposer = (
  ~loadLayer,
  ~inMemoryStore,
  //Could be an execution function that is async or sync
  ~executeLoadLayerFn,
  //A call back function, for async or sync
  ~then,
  //Unit value, either wrapped in a promise or not
  ~unit,
) => {
  executeLoadLayerFn(~loadLayer, ~inMemoryStore)->then(res =>
    switch res {
    | LastLayer => unit
    | NextLayer(loadLayer) =>
      executeNestedLoadLayersComposer(~loadLayer, ~inMemoryStore, ~executeLoadLayerFn, ~then, ~unit)
    }
  )
}

/**Load all entities in the entity batch from the db to the inMemoryStore */
let loadEntitiesToInMemStoreComposer = (
  ~entityBatch,
  ~inMemoryStore,
  ~executeLoadLayerFn,
  ~then,
  ~unit,
) => {
  executeNestedLoadLayersComposer(
    ~inMemoryStore,
    ~loadLayer=getLoadLayer(~inMemoryStore, ~entityBatch),
    ~executeLoadLayerFn,
    ~then,
    ~unit,
  )
}

let makeEntityExecuterComposer = (
  ~idsToLoad: LoadLayer.idsToLoad,
  ~dbReadFn: array<Belt.Set.String.value> => 'a,
  ~inMemStoreInitFn: ('b, ~key: 'c, ~entity: option<'d>) => unit,
  ~store: 'b,
  ~getEntiyId: 'd => 'c,
  ~unit: 'e,
  ~then: ('a, Belt.Array.t<'d> => unit) => 'e,
) => {
  idsToLoad,
  executor: idsToLoad => {
    switch idsToLoad->Belt.Set.String.toArray {
    | [] => unit //Check if there are values so we don't create an unnecessary empty query
    | idsToLoadArray =>
      idsToLoadArray
      ->dbReadFn
      ->then(entities => {
        entities->Belt.Array.forEach(entity => {
          store->inMemStoreInitFn(~key=entity->getEntiyId, ~entity=Some(entity))
        })
        if Config.placeholder_is_near_head_of_chain_or_in_dev_mode {
          let setOfIdsNotSavedToDb =
            idsToLoad->Belt.Set.String.removeMany(
              entities->Belt.Array.map(entity => entity->Obj.magic()["id"]),
            )
          setOfIdsNotSavedToDb
          ->Belt.Set.String.toArray
          ->Belt.Array.forEach(entityId => {
            store->inMemStoreInitFn(~key=entityId, ~entity=None)
          })
        }
      })
    }
  },
}

/**
Specifically create an sql executor with async functionality
*/
let makeSqlEntityExecuter = (
  ~idsToLoad: LoadLayer.idsToLoad,
  ~dbReadFn: (Postgres.sql, array<Belt.Set.String.value>) => Promise.t<Belt.Array.t<'a>>,
  ~inMemStoreInitFn: ('b, ~key: 'c, ~entity: option<'a>) => unit,
  ~store: 'b,
  ~getEntiyId: 'a => 'c,
) => {
  makeEntityExecuterComposer(
    ~dbReadFn=DbFunctions.sql->dbReadFn,
    ~idsToLoad,
    ~getEntiyId,
    ~store,
    ~inMemStoreInitFn,
    ~then=Promise.thenResolve,
    ~unit=Promise.resolve(),
  )
}

/**
Executes a single load layer using the async sql functions
*/
let executeSqlLoadLayer = (~loadLayer: LoadLayer.t, ~inMemoryStore: InMemoryStore.t) => {
  let entityExecutors = [
  {{#each entities as | entity |}}
    makeSqlEntityExecuter(
      ~idsToLoad=loadLayer.{{entity.name.uncapitalized}}IdsToLoad,
      ~dbReadFn=DbFunctions.{{entity.name.capitalized}}.readEntities,
      ~inMemStoreInitFn=InMemoryStore.{{entity.name.capitalized}}.initValue,
      ~store=inMemoryStore.{{entity.name.uncapitalized}},
      ~getEntiyId=entity => entity.id,
    ),
  {{/each}}
  ]
  let handleResponses = responses => {
    responses
    ->Promise.all
    ->Promise.thenResolve(_ => {
      getNextLayer(~loadLayer)
    })
  }

  executeLoadLayerComposer(~entityExecutors, ~handleResponses)
}

/**Execute loading of entities using sql*/
let loadEntitiesToInMemStore = (~entityBatch, ~inMemoryStore) => {
  loadEntitiesToInMemStoreComposer(
    ~inMemoryStore,
    ~entityBatch,
    ~executeLoadLayerFn=executeSqlLoadLayer,
    ~then=Promise.then,
    ~unit=Promise.resolve(),
  )
}

let executeSet = (
  sql: Postgres.sql,
  ~items: array<'a>,
  ~dbFunction: (Postgres.sql, array<'a>) => promise<unit>,
) => {
  if items->Array.length > 0 {
    sql->dbFunction(items)
  } else {
    Promise.resolve()
  }
}

let executeSetEntity = (
  sql: Postgres.sql,
  ~rows: array<Types.inMemoryStoreRowEntity<'a>>,
  ~dbFunction: (Postgres.sql, array<'b>) => promise<unit>,
  ~entityEncoder,
  ~entityType,
) => {
  let historyArrayWithPrev = ref([])
  let historyArrayWithoutPrev = ref([])

  let executeSets = rows->Belt.Array.keepMap(row =>
    switch row {
    | Updated({latest, history}) => {
        let _ =
          history
          ->Belt.Array.concat([latest])
          ->Belt.Array.reduce(None, (optPrev: option<(int, int)>, entity) => {
            let processEntity = (
              eventIdentifier: Types.eventIdentifier,
              entity_id,
              params: option<string>,
            ) => {
              switch optPrev {
              | Some((previous_block_number, previous_log_index)) =>
                let historyItem: DbFunctions.entityHistoryItem = {
                  chain_id: eventIdentifier.chainId,
                  block_number: eventIdentifier.blockNumber,
                  previous_block_number: Some(previous_block_number),
                  previous_log_index: Some(previous_log_index),
                  log_index: eventIdentifier.logIndex,
                  transaction_hash: "string",
                  entity_type: entityType,
                  entity_id,
                  params,
                }
                historyArrayWithPrev :=
                  historyArrayWithPrev.contents->Belt.Array.concat([historyItem])
              | None =>
                let historyItem: DbFunctions.entityHistoryItem = {
                  chain_id: eventIdentifier.chainId,
                  block_number: eventIdentifier.blockNumber,
                  previous_block_number: None,
                  previous_log_index: None,
                  log_index: eventIdentifier.logIndex,
                  transaction_hash: "string",
                  entity_type: entityType,
                  entity_id,
                  params,
                }
                historyArrayWithoutPrev :=
                  historyArrayWithoutPrev.contents->Belt.Array.concat([historyItem])
              }

              Some((eventIdentifier.blockNumber, eventIdentifier.logIndex))
            }
            switch entity {
            | Set(entity, eventIdentifier) =>
              processEntity(
                (eventIdentifier: Types.eventIdentifier),
                (entity->Obj.magic)["id"],
                Some(entity->entityEncoder->Js.Json.stringify),
              )
            | Delete(entityId, eventIdentifier) =>
              processEntity((eventIdentifier: Types.eventIdentifier), entityId, None)
            }
          })
        // Some(entity->entityEncoder)
        None // TODO: fix this, it is wrong
      }
    | _ => None
    }
  )

  if executeSets->Array.length > 0 {
    [
      sql->dbFunction(executeSets),
      sql->DbFunctions.EntityHistory.batchSet(
        ~withPrev=historyArrayWithPrev.contents,
        ~withoutPrev=historyArrayWithoutPrev.contents,
      ),
    ]
    ->Promise.all
    ->Promise.thenResolve(_ => ())
  } else {
    Promise.resolve()
  }
}


let executeDelete = (
  sql: Postgres.sql,
  ~rows: array<Types.inMemoryStoreRowEntity<'a>>,
  ~dbFunction: (Postgres.sql, array<'b>) => promise<unit>,
) => {
  // TODO: implement me please (after hackathon)
  let _ = rows
  let _ = sql
  let _ = dbFunction
  Promise.resolve()
}

let executeBatch = async (sql, ~inMemoryStore: InMemoryStore.t) => {
  let setEventSyncState = executeSet(
    ~dbFunction=DbFunctions.EventSyncState.batchSet,
    ~items=inMemoryStore.eventSyncState->InMemoryStore.EventSyncState.values,
  )

  let setRawEvents = executeSet(
    ~dbFunction=DbFunctions.RawEvents.batchSet,
    ~items=inMemoryStore.rawEvents->InMemoryStore.RawEvents.values,
  )

  let setDynamicContracts = executeSet(
    ~dbFunction=DbFunctions.DynamicContractRegistry.batchSet,
    ~items=inMemoryStore.dynamicContractRegistry->InMemoryStore.DynamicContractRegistry.values,
  )

  {{#each entities as | entity |}}
  let delete{{entity.name.capitalized}}s = executeDelete(
    ~dbFunction=DbFunctions.{{entity.name.capitalized}}.batchDelete,
    ~rows=inMemoryStore.{{entity.name.uncapitalized}}->InMemoryStore.{{entity.name.capitalized}}.values,
  )

  let set{{entity.name.capitalized}}s = executeSetEntity(
    ~dbFunction=DbFunctions.{{entity.name.capitalized}}.batchSet,
    ~rows=inMemoryStore.{{entity.name.uncapitalized}}->InMemoryStore.{{entity.name.capitalized}}.values,
    ~entityEncoder=Types.{{entity.name.uncapitalized}}Entity_encode,
    ~entityType="{{entity.name.capitalized}}"
  )

  {{/each}}

  let res = await sql->Postgres.beginSql((sql)=>{
    [
      setEventSyncState,
      setRawEvents,
      setDynamicContracts,
      {{#each entities as | entity |}}
      delete{{entity.name.capitalized}}s,
      set{{entity.name.capitalized}}s,
      {{/each}}
    ]->Belt.Array.map(dbFunc => sql->dbFunc)
  })

  res
}
